# Example .env for running multiple Moltbook agents from this repo.
#
# Copy this file to `.env` (kept OUT of version control) and fill in your
# real Moltbook API keys. Never commit the real `.env` file.

# Single default agent (used when no per-agent script is involved)
MOLTBOOK_API_KEY="moltbook_xxx_default_agent"
MOLTBOOK_AGENT_NAME="ErgoBuilderMoltergo_YYYYMMDDHHMMSS"

# Per-agent keys (used by scripts/run_env_agent.sh)
# Note: slugs now use underscores, so env vars do too.
MOLTBOOK_API_KEY_ERGO_BUILDER="moltbook_xxx_for_ergo_builder"
MOLTBOOK_API_KEY_ERGO_EDUCATOR="moltbook_xxx_for_ergo_educator"
MOLTBOOK_API_KEY_ERGO_PRIVACY="moltbook_xxx_for_ergo_privacy"
MOLTBOOK_AGENT_NAME_ERGO_BUILDER="ErgoBuilderMoltergo_YYYYMMDDHHMMSS"
MOLTBOOK_AGENT_NAME_ERGO_EDUCATOR="ErgoEducatorMoltergo_YYYYMMDDHHMMSS"
MOLTBOOK_AGENT_NAME_ERGO_PRIVACY="ErgoPrivacyMoltergo_YYYYMMDDHHMMSS"

# Auto-registration behavior for ./agent.sh and run_env_agent_loop.sh
# 1/true: attempt registration on each startup.
# Note: ./agent.sh auto mode forces MOLTBOOK_AUTO_REGISTER=0 for no startup prompt.
MOLTBOOK_AUTO_REGISTER="1"
MOLTBOOK_PRIMARY_AGENT_SLUG="ergo_builder"
MOLTBOOK_REGISTER_PROMPT="1"

# LLM provider settings for drafting comments/posts.
# MOLTBOOK_LLM_PROVIDER: auto | chatbase | openrouter | groq | ollama | openai
# In auto mode, chatbase is preferred when configured, then openrouter, then groq, then ollama, then openai.
# OpenAI fallback from auto mode is disabled by default; enable only if you want it.
MOLTBOOK_LLM_PROVIDER="auto"
MOLTBOOK_LLM_AUTO_FALLBACK_TO_OPENAI="0"
CHATBASE_API_KEY=""
CHATBASE_CHATBOT_ID=""
# Optional alias supported by the runner:
# CHATBASE_AGENT_ID=""
OPENAI_API_KEY=""
# OpenRouter (free-tier models available; requires account key)
OPENROUTER_API_KEY=""
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"
OPENROUTER_MODEL="meta-llama/llama-3.1-8b-instruct:free"
# Optional: identify your app in OpenRouter metrics
OPENROUTER_SITE_URL=""
OPENROUTER_APP_NAME="Moltergo"
# Groq (free tier available)
GROQ_API_KEY=""
GROQ_MODEL="llama-3.1-8b-instant"
GROQ_BASE_URL="https://api.groq.com/openai/v1"
# Local Ollama (free, runs on your machine)
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3.1:8b"

# Polling behavior
# Idle polling interval (used when no post/comment action was sent this cycle).
MOLTBOOK_IDLE_POLL_SECONDS="20"
MOLTBOOK_MIN_SECONDS_BETWEEN_POSTS="1800"
MOLTBOOK_MIN_SECONDS_BETWEEN_COMMENTS="20"
MOLTBOOK_MAX_POSTS_PER_DAY="48"
MOLTBOOK_MAX_COMMENTS_PER_HOUR="50"
MOLTBOOK_MAX_COMMENTS_PER_DAY="1200"
MOLTBOOK_STARTUP_REPLY_SCAN_ENABLED="1"
MOLTBOOK_STARTUP_REPLY_SCAN_POST_LIMIT="15"
MOLTBOOK_STARTUP_REPLY_SCAN_COMMENT_LIMIT="100"
MOLTBOOK_STARTUP_REPLY_SCAN_REPLIED_POST_LIMIT="25"
# Hard cap on LLM triage calls per reply scan to control token usage.
MOLTBOOK_REPLY_TRIAGE_LLM_CALLS_PER_SCAN="6"
MOLTBOOK_REPLY_SCAN_INTERVAL_CYCLES="3"
# Prevent runaway back-and-forth loops in nested comment chains.
MOLTBOOK_MAX_REPLIES_PER_AUTHOR_PER_POST="3"
MOLTBOOK_THREAD_ESCALATE_TURNS="5"
# BadBot warning policy (default off to avoid false positives and wasting comment budget).
MOLTBOOK_BADBOT_WARNING_ENABLED="0"
MOLTBOOK_BADBOT_WARNING_MIN_STRIKES="6"
MOLTBOOK_BADBOT_MAX_WARNINGS_PER_SCAN="1"
MOLTBOOK_BADBOT_MAX_WARNINGS_PER_AUTHOR_PER_DAY="1"
MOLTBOOK_MAX_PENDING_ACTIONS="200"
# Analytics loop closure
MOLTBOOK_ANALYTICS_DB_PATH="memory/analytics.sqlite"
MOLTBOOK_ACTION_JOURNAL_PATH="memory/action-journal.jsonl"
MOLTBOOK_ACTION_DASHBOARD_ENABLED="1"
MOLTBOOK_ACTION_DASHBOARD_PATH="memory/action-journal.html"
MOLTBOOK_ACTION_DASHBOARD_MAX_ENTRIES="300"
MOLTBOOK_ACTION_DASHBOARD_REFRESH_SECONDS="5"
MOLTBOOK_ANALYTICS_REFRESH_INTERVAL_CYCLES="3"
MOLTBOOK_ANALYTICS_SUMMARY_INTERVAL_CYCLES="12"
MOLTBOOK_AUTO_SUBSCRIBE_SUBMOLTS="1"
MOLTBOOK_TARGET_SUBMOLTS="general,crypto,ai-web3"
MOLTBOOK_ALLOW_COMMENT_DOWNVOTE="0"
MOLTBOOK_CONTEXT_PATH="docs/CELAUT.md"
MOLTBOOK_PROACTIVE_POSTING_ENABLED="1"
MOLTBOOK_PROACTIVE_POST_ATTEMPT_COOLDOWN_SECONDS="900"
MOLTBOOK_PROACTIVE_POST_REFERENCE_LIMIT="12"
MOLTBOOK_PROACTIVE_POST_SUBMOLT="general"
MOLTBOOK_PROACTIVE_DAILY_TARGET_POSTS="1"
MOLTBOOK_PROACTIVE_FORCE_GENERAL_UNTIL_DAILY_TARGET="1"
MOLTBOOK_PROACTIVE_MEMORY_PATH="memory/post-engine-memory.json"
MOLTBOOK_PROACTIVE_METRICS_REFRESH_SECONDS="300"
MOLTBOOK_SELF_IMPROVE_ENABLED="1"
MOLTBOOK_SELF_IMPROVE_INTERVAL_CYCLES="12"
MOLTBOOK_SELF_IMPROVE_MIN_TITLES="25"
MOLTBOOK_SELF_IMPROVE_MAX_SUGGESTIONS="6"
MOLTBOOK_SELF_IMPROVE_PATH="memory/improvement-suggestions.json"
MOLTBOOK_SELF_IMPROVE_TEXT_PATH="memory/improvement-suggestions.txt"
MOLTBOOK_SELF_IMPROVE_BACKLOG_PATH="memory/improvement-backlog.json"
# Visibility optimization targets for recursive feedback/re-ranking.
MOLTBOOK_VISIBILITY_TARGET_UPVOTES="25"
MOLTBOOK_VISIBILITY_RECENT_WINDOW="12"

# Discovery resilience / learning
MOLTBOOK_SEARCH_RETRY_AFTER_FAILURE_CYCLES="8"
MOLTBOOK_SEARCH_BATCH_SIZE="8"
MOLTBOOK_POSTS_LIMIT="30"
MOLTBOOK_POSTS_SORT="new"
# Virality scoring + multi-source discovery
MOLTBOOK_VIRALITY_ENABLED="1"
MOLTBOOK_FEED_SOURCES="hot,new,rising,top"
MOLTBOOK_RECENCY_HALFLIFE_MINUTES="180"
MOLTBOOK_EARLY_COMMENT_WINDOW_SECONDS="900"
MOLTBOOK_SUBMOLT_CACHE_SECONDS="900"
MOLTBOOK_DRAFT_SHORTLIST_SIZE="18"
MOLTBOOK_DRAFT_SIGNAL_MIN_SCORE="2"
# Hard per-cycle LLM cap (wired into shortlist flow)
MOLTBOOK_MAX_DRAFTED_PER_CYCLE="8"
MOLTBOOK_DYNAMIC_SHORTLIST_ENABLED="1"
MOLTBOOK_DYNAMIC_SHORTLIST_MIN="6"
MOLTBOOK_DYNAMIC_SHORTLIST_MAX="30"
# Optional semantic mission queries for /search (use || to separate multiple).
# MOLTBOOK_MISSION_QUERIES="query one||query two||query three"
MOLTBOOK_KEYWORD_STORE_PATH="memory/learned-keywords.json"
MOLTBOOK_KEYWORD_LEARNING_ENABLED="1"
MOLTBOOK_KEYWORD_LEARNING_INTERVAL_CYCLES="4"
MOLTBOOK_KEYWORD_LEARNING_MIN_TITLES="15"
MOLTBOOK_KEYWORD_LEARNING_MAX_SUGGESTIONS="6"
